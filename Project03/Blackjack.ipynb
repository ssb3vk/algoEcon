{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Blackjack",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle"
      ],
      "metadata": {
        "id": "7uI5FNKKhEj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reset probability pickles\n",
        "if input(\"Are you sure you want to flush data?\") == 'y':\n",
        "  bot_state_specific = True\n",
        "  bot_strategy = 3\n",
        "  filename = \"bj_belief_\" + str(bot_strategy) + (\"s\" * bot_state_specific)    \n",
        "  if bot_state_specific:\n",
        "    temp_belief = np.ones((26,2)) / 2\n",
        "  else:\n",
        "    temp_belief = np.ones(2) / 2\n",
        "  tempfile = open(filename, 'wb')\n",
        "  pickle.dump((1,temp_belief), tempfile)\n",
        "  tempfile.close()\n",
        "  print(\"FLUSHED DATA\")\n",
        "else:\n",
        "  print(\"no data flushed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqBf6QH-DnFV",
        "outputId": "a2018be1-0e88-46dd-985a-8a13e6f579d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Are you sure you want to flush data?y\n",
            "FLUSHED DATA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHz-noUCf660"
      },
      "outputs": [],
      "source": [
        "# void player.setup((player card 1, player card 2), dealer card, [(opp card 1, ...)...])\n",
        "# void player.deal(int card)\n",
        "# bool player.hit() returns true if player hits and false if player stands\n",
        "# void player.feedback(bool won?)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class HumanPlayer:\n",
        "  def __init__(self, my_hand, opp_hands, num_decks=6):\n",
        "    self.hand = [my_hand[0], my_hand[1]] # list of integers (repeats and appends allowed)\n",
        "    self.opp_hands = opp_hands # list of tuples\n",
        "    self.num_decks = num_decks # number of decks in circulation\n",
        "    \n",
        "    self.card_totals = {} # maps a card number to amount of cards in circulation (in deck or face down)\n",
        "    for number_card in range(1,10): # 1 = A\n",
        "      self.card_totals[number_card] = 4*num_decks\n",
        "    self.card_totals[10] = 16*num_decks  # 10, J, Q, K\n",
        "    for card in self.hand:\n",
        "      self.card_totals[card] -= 1\n",
        "    for opp_hand in self.opp_hands:\n",
        "      for card in opp_hand:\n",
        "        self.card_totals[card] -= 1\n",
        "    print(\"[Human] Your starting hand: \" + str(self.hand))\n",
        "\n",
        "\n",
        "  def deal(self, card):\n",
        "    self.hand.append(card)\n",
        "    self.card_totals[card] -= 1\n",
        "    print(\"[Human] You've been dealt a card: \" + str(card))\n",
        "    print(\"[Human] Your current hand: \" + str(self.hand))\n",
        "\n",
        "  def hit(self):\n",
        "    print(\"[Human] Type 'h' to hit, otherwise stand: \", end=\"\")\n",
        "    response = input()\n",
        "    if (response == 'h') or (response == 'H'):\n",
        "      return True  # player decides to hit\n",
        "    return False # player decides to stand\n",
        "\n",
        "  def win(self, reward):\n",
        "    ################ REWARD\n",
        "    print(\"[Human] You won \" + str(reward) + \" units!\")\n",
        "\n",
        "  def lose(self, punishment):\n",
        "    ################ PUNISH\n",
        "    print(\"[Human] You netted \" + str(punishment) + \" units.\")"
      ],
      "metadata": {
        "id": "ej9i3OJcVE54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AutoPlayer:\n",
        "  def __init__(self, my_hand, opp_hands, num_decks=6, state_specific=True, name=\"Robot\", iteration=1, prior_belief=None, strategy=0, verbose=True):\n",
        "    self.hand = [my_hand[0], my_hand[1]] # list of integers (repeats and appends allowed)\n",
        "    self.opp_hands = opp_hands # list of tuples\n",
        "    self.num_decks = num_decks # number of decks in circulation\n",
        "    self.state_specific = state_specific\n",
        "    self.name = name\n",
        "    self.last_move = (-1, 0)  # represents state, 0 for stand and 1 for hit\n",
        "    self.t = iteration # with t^th robot are we training?\n",
        "    # sqrt (num actions * 2 * log(num_actions) / t)\n",
        "    self.gamma = min(1, math.sqrt(2 * 2 * math.log(2) / (self.t) ) )\n",
        "    if self.state_specific:\n",
        "      self.strategy = strategy\n",
        "    else:\n",
        "      self.strategy = 0\n",
        "\n",
        "    self.card_totals = {} # maps a card number to amount of cards in circulation (in deck or face down)\n",
        "    for number_card in range(1,10): # 1 = A\n",
        "      self.card_totals[number_card] = 4*num_decks\n",
        "    self.card_totals[10] = 16*num_decks  # 10, J, Q, K\n",
        "    for card in self.hand:\n",
        "      self.card_totals[card] -= 1\n",
        "    for opp_hand in self.opp_hands:\n",
        "      for card in opp_hand:\n",
        "        self.card_totals[card] -= 1\n",
        "    if verbose : print(\"[\" + self.name + \"] Starting hand: \" + str(self.hand))\n",
        "\n",
        "    ############# PICKLE LOAD\n",
        "    if prior_belief is not None:\n",
        "      self.belief = prior_belief\n",
        "    else:\n",
        "      if self.state_specific:\n",
        "        self.belief = np.ones((26,2)) / 2\n",
        "      else:\n",
        "        self.belief = np.ones(2) / 2\n",
        "    self.prior_belief = np.copy(self.belief)\n",
        "\n",
        "    '''\n",
        "    Type I: bold (epsilon greedy) (naive) (strategy 0)\n",
        "    action_prob = (1-epsilon)*belief + (epsilon * 1/2)\n",
        "\n",
        "    Type II: cautious (game programmed) (strategy 1)  [ONLY STATE SPECIFIC]\n",
        "    action_prob = (1-p_bust)*belief\n",
        "\n",
        "    Type III: mix (strategy 2)   [ONLY STATE SPECIFIC]\n",
        "    action_prob = (1-epsilon)*(1-p_bust)*belief + (epsilon * 1/2)\n",
        "    '''\n",
        "      \n",
        "    # action probability 0 = stand, 1 = hit\n",
        "    if (self.strategy == 0):\n",
        "      self.action_probability = (1.0 - self.gamma) * self.belief + self.gamma / 2\n",
        "    elif self.strategy == 1:\n",
        "      self.action_probability = (1.0-self.p_bust()) * self.belief\n",
        "    else: # strategy = 2\n",
        "      self.action_probability = ((1.0 - self.gamma)*(1.0-self.p_bust())) * self.belief + self.gamma / 2\n",
        "\n",
        "    # normalize probabilities to sum to 1\n",
        "    if self.state_specific:\n",
        "      self.action_probability /= np.sum(self.action_probability, axis=1)[:,None]\n",
        "    else:\n",
        "      self.action_probability /= np.sum(self.action_probability)\n",
        "\n",
        "  def p_bust(self):\n",
        "    # returns the probability that hitting will put agent over 21 in any case\n",
        "    total_cards_in_deck = 0\n",
        "    for card_val in self.card_totals:\n",
        "      total_cards_in_deck += self.card_totals[card_val]\n",
        "    threshold = 21 - sum(self.hand) # if over threshold, we bust\n",
        "    if threshold >= 10:\n",
        "      return 0   # if we need more than 10 to bust, no card will force us to bust\n",
        "    bust_cards_in_deck = 0\n",
        "    for card_val in self.card_totals:\n",
        "      if card_val > threshold:\n",
        "        bust_cards_in_deck += self.card_totals[card_val]\n",
        "    return bust_cards_in_deck/total_cards_in_deck\n",
        "\n",
        "\n",
        "  def values(self):\n",
        "    possible_values = [np.sum(self.hand)]\n",
        "    for i in range(self.hand.count(1)):\n",
        "      possible_values.append(possible_values[0] + ((i+1)*10))  # account for Ace dual value\n",
        "    return tuple(possible_values)\n",
        "\n",
        "\n",
        "  def deal(self, card):\n",
        "    self.hand.append(card)\n",
        "    self.card_totals[card] -= 1\n",
        "    if verbose : print(\"[\" + self.name + \"] Dealt card: \" + str(card))\n",
        "    if verbose : print(\"[\" + self.name + \"] Current hand: \" + str(self.hand))\n",
        "\n",
        "\n",
        "  def hit(self):\n",
        "    if 21 in self.values(): # already most optimal position\n",
        "      if verbose : print(\"[\" + self.name + \"] Blackjack! I stand.\")\n",
        "      return False  # stand\n",
        "    if min(self.values()) > 21:\n",
        "      if verbose : print(\"[\" + self.name + \"] Bust! I must stand.\")\n",
        "      return False  # busted... punish?\n",
        "\n",
        "    decision = False\n",
        "\n",
        "    curr_state = -1\n",
        "    \n",
        "    if self.state_specific:\n",
        "      if (1 in self.hand) and (np.sum(self.hand)-1 < 10):  # ace present in hand. if OTHER cards add up to more than 10, ace becomes default 1. if they add up to exactly 10, then you would've auto-stood at 21\n",
        "        curr_state = np.sum(self.hand) + 15\n",
        "      else:  # all cards in hand are non-aces\n",
        "        curr_state = np.sum(self.hand) - 4\n",
        "      # print(self.hand)\n",
        "      # print(curr_state)\n",
        "      decision = bool(np.random.choice(2, p=self.action_probability[curr_state,:]))\n",
        "    else:\n",
        "      decision = bool(np.random.choice(2, p=self.action_probability))\n",
        "\n",
        "\n",
        "    self.last_move = (curr_state, int(decision))\n",
        "\n",
        "    if decision == 1:\n",
        "      if verbose : print(\"[\" + self.name + \"] I choose to hit!\")\n",
        "      return True  # player decides to hit\n",
        "    else:\n",
        "      if verbose : print(\"[\" + self.name + \"] I choose to stand.\")\n",
        "      return False # player decides to stand\n",
        "\n",
        "\n",
        "  def feedback(self, reward):\n",
        "    self.t += 1\n",
        "    if self.state_specific:\n",
        "      estimatedReward = reward / self.action_probability[self.last_move[0],self.last_move[1]]\n",
        "      self.belief[self.last_move[0],self.last_move[1]] *= math.exp(estimatedReward * self.gamma / 2) \n",
        "      print(self.belief)\n",
        "    else:\n",
        "      estimatedReward = reward / self.action_probability[self.last_move[1]]\n",
        "      self.belief[self.last_move[1]] *= math.exp(estimatedReward * self.gamma / 2)\n",
        "    ########## PIKCLE DUMP \n",
        "\n",
        "\n",
        "  def win(self, reward):\n",
        "    if verbose : print(\"[\" + self.name + \"] Yay! I won \" + str(reward) + \" units!\")\n",
        "    # self.feedback(reward)\n",
        "\n",
        "\n",
        "  def lose(self, punishment):\n",
        "    if verbose : print(\"[\" + self.name + \"] Aw, I netted \" + str(punishment) + \" units.\")\n",
        "    # self.feedback(punishment)\n",
        "\n",
        "  # def change_in_belief(self):\n",
        "  #   return self.belief - self.prior_belief\n",
        "\n",
        "  def change_belief(self, reward):\n",
        "    if self.state_specific:\n",
        "      estimatedReward = reward / self.action_probability[self.last_move[0],self.last_move[1]]\n",
        "    else:\n",
        "      estimatedReward = reward / self.action_probability[self.last_move[1]]\n",
        "    return (self.last_move[0],self.last_move[1], math.exp(estimatedReward * self.gamma / 2) )"
      ],
      "metadata": {
        "id": "243IX6rnhJ4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bust(hand):\n",
        "  return np.sum(hand) > 21\n",
        "\n",
        "def possible_values(hand):\n",
        "  possible_values = [np.sum(hand)]\n",
        "  for i in range(hand.count(1)):\n",
        "    possible_values.append(possible_values[0] + ((i+1)*10))  # account for Ace dual value\n",
        "  return tuple(possible_values)"
      ],
      "metadata": {
        "id": "dd--vfuyXNrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dealer = True\n",
        "human = False\n",
        "num_decks = 1\n",
        "num_players = 5  \n",
        "\n",
        "bot_state_specific = True\n",
        "bot_strategy = 3\n",
        "\n",
        "possible_settings = [(False, 1),] + [(True, x) for x in range(3)]\n",
        "\n",
        "verbose = False\n",
        "\n",
        "num_epochs = 1000\n",
        "for epoch in range(num_epochs):\n",
        "  filename = \"bj_belief_\" + str(bot_strategy) + (\"s\" * bot_state_specific)    \n",
        "  tempfile = open(filename, 'rb')\n",
        "  (generation, prior_belief) = pickle.load(tempfile)  \n",
        "  # generation = how many rounds bot has been trained\n",
        "  # prior_belief = trained beliefs for picking any given action\n",
        "  tempfile.close()\n",
        "\n",
        "  # at least 2 if dealer is not present, otherwise 1\n",
        "  if (not dealer):\n",
        "    num_players = max(num_players, 2)\n",
        "  else:\n",
        "    num_players = max(num_players, 1)\n",
        "\n",
        "  human_turn = np.random.choice(num_players)\n",
        "  names = [\"Bot \" + str(i) for i in range(num_players)]\n",
        "  if human:\n",
        "    names[human_turn] = \"Human\"\n",
        "  if dealer:\n",
        "    names.append(\"Dealer\")\n",
        "\n",
        "  if verbose : print(\"Players: \" + str(names))\n",
        "\n",
        "  # create and shuffle deck\n",
        "  deck = []\n",
        "  for nd in range(num_decks):\n",
        "    for i in range(1,10):\n",
        "      for suit in range(4):\n",
        "        deck.append(i)\n",
        "    for face in range(16):\n",
        "      deck.append(10)\n",
        "  np.random.shuffle(deck)\n",
        "\n",
        "  # deal initial cards\n",
        "  all_hands = []  # length = num_players (+1 if dealer exists)\n",
        "  for p in range(num_players):\n",
        "    all_hands.append([deck.pop(), deck.pop()])\n",
        "\n",
        "  if(dealer):\n",
        "    next_card = deck.pop()\n",
        "    all_hands.append([next_card, ])\n",
        "\n",
        "  if verbose : print(\"Starting Hands: \" + str(all_hands))\n",
        "\n",
        "  players = []\n",
        "\n",
        "  for p in range(num_players):  # players go one at a time, COULD CHANGE THIS LATER?\n",
        "    if verbose : print()\n",
        "    curr_hand = tuple(all_hands[p])\n",
        "    curr_opp_hands = []\n",
        "    for p2 in range(len(all_hands)):\n",
        "      if p2 != p:\n",
        "        curr_opp_hands.append(tuple(all_hands[p2]))\n",
        "    \n",
        "    if human and (p == human_turn):\n",
        "      curr_player = HumanPlayer(curr_hand,curr_opp_hands,num_decks=num_decks)\n",
        "    else:\n",
        "      curr_player = AutoPlayer(curr_hand,curr_opp_hands,num_decks=num_decks, state_specific=bot_state_specific, name=names[p], strategy=bot_strategy, iteration=generation, verbose=verbose, prior_belief=prior_belief)\n",
        "    players.append(curr_player)\n",
        "\n",
        "    while(curr_player.hit()):\n",
        "      # deal player a card\n",
        "      curr_card = deck.pop()\n",
        "      all_hands[p].append(curr_card)\n",
        "      curr_player.deal(curr_card)\n",
        "      if bust(all_hands[p]):\n",
        "        if verbose : print(\"[\" + names[p] + \"] Bust!\")\n",
        "        break\n",
        "\n",
        "  # dealer's behavior, no variability\n",
        "  if dealer:\n",
        "    if verbose : print()\n",
        "    while max(possible_values(all_hands[-1])) < 17:\n",
        "      curr_card = deck.pop()\n",
        "      all_hands[-1].append(curr_card)\n",
        "      if verbose : print(\"[Dealer] Draws card: \" + str(curr_card))\n",
        "      if verbose : print(\"[Dealer] Hand: \" + str(all_hands[-1]))\n",
        "\n",
        "  if verbose : print()\n",
        "  # decide who won\n",
        "  winners = []\n",
        "  max_score = -1\n",
        "  for p in range(len(all_hands)):\n",
        "    for valuation in possible_values(all_hands[p]):\n",
        "      if valuation > 21:  # don't want to award win to a valuation that busts\n",
        "        continue\n",
        "      if valuation > max_score:\n",
        "        max_score = valuation\n",
        "        winners = [p,]\n",
        "      elif valuation == max_score:\n",
        "        winners.append(p)\n",
        "  # print(winners)\n",
        "\n",
        "  if(len(winners) > 0):\n",
        "    reward = (len(all_hands) * 1.0/len(winners))-1\n",
        "  else:\n",
        "    reward = -1  # everyone busted\n",
        "\n",
        "  final_belief = prior_belief \n",
        "\n",
        "  generation += 1\n",
        "\n",
        "  # print(\"Before: \" + str(final_belief))\n",
        "  for p in range(num_players):\n",
        "    if p in winners:\n",
        "      players[p].win(reward)  # maybe reward inversely proportional to number of winners?\n",
        "      # each player and dealer adds 1 unit to pool, which is split amongst winners\n",
        "      # subtract one for initial investment\n",
        "      curr_reward = reward\n",
        "    else:\n",
        "      players[p].lose(-1)\n",
        "      curr_reward = -1\n",
        "    if (not human) or (human and (p != human_turn)):\n",
        "      change = players[p].change_belief(curr_reward)\n",
        "      # print(change)\n",
        "      if bot_state_specific:\n",
        "        final_belief[change[0],change[1]] *= change[2]\n",
        "      else:\n",
        "        final_belief[change[1]]*=change[2]\n",
        "  \n",
        "  if bot_state_specific:\n",
        "    final_belief /= np.sum(final_belief, axis=1)[:,None]\n",
        "  else:\n",
        "    final_belief /= np.sum(final_belief)\n",
        "\n",
        "  # print(\"After: \" + str(final_belief))\n",
        "\n",
        "  tempfile = open(filename, 'wb')\n",
        "  pickle.dump((generation,final_belief), tempfile)\n",
        "  tempfile.close()\n",
        "\n",
        "  if(num_players in winners):\n",
        "    if verbose : print(\"[Dealer] House wins \" + str(reward) + \" units.\")\n",
        "  elif dealer:  # dealer in the game but not in winners\n",
        "    if verbose : print(\"[Dealer] House netted -1 unit.\")"
      ],
      "metadata": {
        "id": "WD5rT3A-Gt0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bot_state_specific = True\n",
        "bot_strategy = 3\n",
        "filename = \"bj_belief_\" + str(bot_strategy) + (\"s\" * bot_state_specific)    \n",
        "tempfile = open(filename, 'rb')\n",
        "(generation, prior_belief) = pickle.load(tempfile)  \n",
        "# generation = how many rounds bot has been trained\n",
        "# prior_belief = trained beliefs for picking any given action\n",
        "tempfile.close()\n",
        "(generation, prior_belief)"
      ],
      "metadata": {
        "id": "fl2Hxt5gCOIp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88af1381-d64d-425e-a191-fce5c28838d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1001, array([[3.80002930e-01, 6.19997070e-01],\n",
              "        [3.56217148e-02, 9.64378285e-01],\n",
              "        [1.93970519e-02, 9.80602948e-01],\n",
              "        [3.62329946e-02, 9.63767005e-01],\n",
              "        [8.97889152e-03, 9.91021108e-01],\n",
              "        [1.37575365e-05, 9.99986242e-01],\n",
              "        [6.03246635e-07, 9.99999397e-01],\n",
              "        [1.17075389e-13, 1.00000000e+00],\n",
              "        [8.73057200e-08, 9.99999913e-01],\n",
              "        [3.91958672e-14, 1.00000000e+00],\n",
              "        [1.64206300e-06, 9.99998358e-01],\n",
              "        [1.92224825e-08, 9.99999981e-01],\n",
              "        [2.34110698e-06, 9.99997659e-01],\n",
              "        [8.87136858e-06, 9.99991129e-01],\n",
              "        [8.34536678e-02, 9.16546332e-01],\n",
              "        [9.99999586e-01, 4.14384182e-07],\n",
              "        [1.00000000e+00, 2.55781094e-28],\n",
              "        [3.53109121e-01, 6.46890879e-01],\n",
              "        [3.33286078e-02, 9.66671392e-01],\n",
              "        [5.30042708e-02, 9.46995729e-01],\n",
              "        [1.41719440e-03, 9.98582806e-01],\n",
              "        [1.12841235e-01, 8.87158765e-01],\n",
              "        [6.90669053e-02, 9.30933095e-01],\n",
              "        [2.63626238e-02, 9.73637376e-01],\n",
              "        [1.04712483e-03, 9.98952875e-01],\n",
              "        [1.00000000e+00, 3.10349330e-24]]))"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load pickle file\n",
        "tempfile = open(filename, 'rb')\n",
        "(generation, prior_belief) = pickle.load(tempfile)  \n",
        "# generation = how many rounds bot has been trained\n",
        "# prior_belief = trained beliefs for picking any given action\n",
        "tempfile.close()\n",
        "(generation, prior_belief)"
      ],
      "metadata": {
        "id": "BAJlFu4eEIQv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}